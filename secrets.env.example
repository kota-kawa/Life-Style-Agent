# Multi-Agent Platform Configuration
# Defines the base URL for the central platform orchestration
MULTI_AGENT_PLATFORM_BASE=http://web:5050

# --- LLM Provider API Keys ---
# Set the API key for the provider you intend to use.
# The agent supports: openai, claude, gemini, groq.
# You only need to set the key for the provider you are using.

# OpenAI
# OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx

# Anthropic (Claude)
# CLAUDE_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx

# Google (Gemini)
# GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxx
# GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxx

# Groq
# GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxx

# --- Prompt Guard (optional) ---
# PROMPT_GUARD_MODEL=openai/gpt-oss-safeguard-20b
# PROMPT_GUARD_BASE_URL=https://api.groq.com/openai/v1
# PROMPT_GUARD_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxx
# PROMPT_GUARD_FAIL_CLOSED=false
# PROMPT_GUARD_BLOCK_MESSAGE=Sorry, I can't help with that request.

# --- Optional: Custom Base URLs ---
# If you are using a proxy or a compatible API server (e.g. vLLM, Ollama)
# OPENAI_BASE_URL=https://api.openai.com/v1
# GEMINI_API_BASE=https://generativelanguage.googleapis.com/openai/v1

# --- RAG & Embeddings ---
# Configuration for the embedding model used in RAG (Retrieval Augmented Generation)
EMBEDDING_MODEL_NAME=intfloat/multilingual-e5-large
EMBEDDING_DEVICE=cpu

# --- Ingestion Scripts (Optional) ---
# Used when running data ingestion scripts manually
# DOCX_IN_DIR=data/home-topic
# JSONL_OUT_DIR=data/qa_jsonl
# GEMINI_MODEL=gemini-2.5-pro
